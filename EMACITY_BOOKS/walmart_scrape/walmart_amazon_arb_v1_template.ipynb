{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "\n",
    "def walmart_rollbacks(store_code):\n",
    "    '''\n",
    "    Scrapes Walmart.com to find the different items on rollback and returns a tuple of the product name and price.\n",
    "    Parameters:\n",
    "    -----------------------------------------------\n",
    "    store_code: integer of the location of walmart based on given zipcode.\n",
    "    '''\n",
    "    departments = ['furniture', 'hardware', 'fashion', 'electronics', 'toys', 'patio-garden']\n",
    "    records = []\n",
    "    for department in departments:\n",
    "        url = 'https://www.walmart.com/store/'+ str(store_code) + '/' + department\n",
    "        web_html = requests.get(url).text\n",
    "        soup = BeautifulSoup(web_html, 'lxml')\n",
    "    \n",
    "        rollbacks = soup.find_all('div', class_ = 'rollback-result-wrapper')\n",
    "        \n",
    "        #print(department)\n",
    "        \n",
    "        for products in rollbacks:\n",
    "            product_name = products.find('div', style = 'max-height:3em;overflow:hidden').text\n",
    "            product_price = products.find('span', class_ = 'price-characteristic')\n",
    "            if (products.find('span', class_ = 'price-characteristic')):\n",
    "                #print(product_name)\n",
    "                #print(product_price.text)\n",
    "                records.append((product_name, product_price.text))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HART 40-Volt Cordless 12-inch String Trimmer and Blower Combo', '158'),\n",
       " ('HART PowerFit Edger Attachment (for Attachment Capable String Trimmer)',\n",
       "  '67'),\n",
       " ('Merkury Innovations A21 Smart Multicolor LED Bulb, 75W, Dimmable, 2-Pack',\n",
       "  '15'),\n",
       " ('Great Value LED Light Bulb, 4 Watts (40W Equivalent) B10 Deco Lamp E12 Candelabra Base, Dimmable, Soft White, 4-Pack',\n",
       "  '5'),\n",
       " ('Midea 5,000 BTU 115V Mechanical Window Air Conditioner, MAW05M1WWT', '134'),\n",
       " ('Lasko 12\" Desktop Wind Tower Oscillating Multi-Directional Table Fan, T13310, Black',\n",
       "  '19'),\n",
       " ('COAST G34 Alkaline Power 355 Lumen Twist Focusing Handheld LED Flashlight',\n",
       "  '14'),\n",
       " ('Great Value LED Light Bulb, 9 Watts (65W Eqv.) BR30 Floodlight Lamp E26 Base, Dimmable, Soft White, 4-Pack',\n",
       "  '6'),\n",
       " ('Great Value LED Light Bulb, 7 Watts (50W Equivalent) MR16 Lamp GU10 Base, Dimmable, Soft White, 3-Pack',\n",
       "  '3'),\n",
       " ('GE LED 2.5-Watt (25W Equivalent) Soft White Decorative Clear Finish Light Bulbs, 4-Pack',\n",
       "  '9'),\n",
       " ('Merkury Innovations A19 Smart White LED Bulb, 60W, Dimmable, 3-Pack', '15'),\n",
       " ('Gildan Adult Cotton White Crew Short Sleeve T-Shirt, 1-Pack, Small', '2'),\n",
       " (\"Time and Tru Women's Super Soft Fair Isle Low Cut Sock, 3 Pair\", '3'),\n",
       " ('Apple AirPods Pro', '197'),\n",
       " ('SAMSUNG Galaxy Tab S7 128GB Mystic Black (Wi-Fi) S Pen Included - SM-T870NZKAXAR',\n",
       "  '566'),\n",
       " ('Linksys N600 Dual Band WiFi Router, Black Internet Router (2500)', '26'),\n",
       " ('Straight Talk Motorola E, 32GB, Midnight Blue - Prepaid Smartphone', '49'),\n",
       " ('Merkury Innovations A21 Smart Multicolor LED Bulb, 75W, Dimmable, 2-Pack',\n",
       "  '15'),\n",
       " ('NETGEAR - Nighthawk R7450 AC2600 Smart WiFi Router', '139'),\n",
       " ('2-in-1 Snug and Secure Swing - Magenta', '23'),\n",
       " ('Blueys Family and Friends 2.5\" Figures - 8 Pack', '19'),\n",
       " ('Subway Surfers - Sub Surf Spray Crew - Each Sold Separately Vinyl Figure (4\")',\n",
       "  '4'),\n",
       " ('LOL Surprise Remix Hair Flip Dolls - 15 Surprises with Hair Reveal & Music',\n",
       "  '8'),\n",
       " ('Rainbow High Hair Studio  Create Rainbow Hair with Exclusive Doll, Extra-Long Washable Hair Color',\n",
       "  '29'),\n",
       " ('Little Tikes 2-In-1 Snug And Secure Swing - Blue', '23'),\n",
       " ('Love Diana Mystery Shopper Playset With 13 inch Doll Plus 12 Surprises, For Ages 3+',\n",
       "  '34'),\n",
       " ('Cave Club Roaralai Doll (8 - 10-Inch) Prehistoric Fashion Doll with Dinosaur Pet',\n",
       "  '7'),\n",
       " ('Love, Diana Birthday, 6\" Doll', '7'),\n",
       " ('Cave Club Emberly Doll (8 - 10-Inch) Prehistoric Fashion Doll with Dinosaur Pet',\n",
       "  '7'),\n",
       " ('Roundup Ready-To-Use Weed & Grass Killer III with Comfort Wand, 1.33 gal.',\n",
       "  '17'),\n",
       " ('HART 40-Volt Cordless 12-inch String Trimmer and Blower Combo', '158'),\n",
       " ('Ortho Home Defense Insect Killer for Indoor Perimeter 2 (With Comfort Wand), 1.33 Gal.',\n",
       "  '13'),\n",
       " ('Spectracide Weed & Grass Killer, Ready-to-Use, 1-Gallon', '6'),\n",
       " ('HART PowerFit Edger Attachment (for Attachment Capable String Trimmer)',\n",
       "  '67'),\n",
       " ('Roundup For Lawns 1 (Northern) Extended Wand, 1.33 gal., Kills the Root',\n",
       "  '20'),\n",
       " (\"Miracle-Gro Shake 'N Feed Tomato, Fruit & Vegetable Plant Food 4.5lb\",\n",
       "  '10'),\n",
       " (\"Miracle-Gro Shake 'N Feed Rose & Bloom Plant Food Display\", '10'),\n",
       " ('Great Value LED Light Bulb, 7 Watts (50W Equivalent) R20 Floodlight Lamp E26 Medium Base, Dimmable, Soft White, 2-Pack',\n",
       "  '3'),\n",
       " ('Great Value LED Light Bulb, 5 Watts (35W Equivalent) MR16 Lamp GU5.3 Base, Dimmable, Soft White, 3-Pack',\n",
       "  '3')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_rollbacks(1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walmart_inventory():\n",
    "    '''\n",
    "    Scrapes Walmart.com to find the all items in the online store.  Makes a csv file of all of the information we\n",
    "    want.  Returns string complete.\n",
    "    '''\n",
    "    \n",
    "    https://www.walmart.com/browse/home/beds/4044_103150_102547_91837?page=1\n",
    "    https://www.walmart.com/browse/home/beds/4044_103150_102547_91837?page=2\n",
    "    \n",
    "    departments = ['furniture', 'hardware', 'fashion', 'electronics', 'toys', 'patio-garden']\n",
    "    records = []\n",
    "    for department in departments:\n",
    "        url = 'https://www.walmart.com/store/'+ str(store_code) + '/' + department\n",
    "        web_html = requests.get(url).text\n",
    "        soup = BeautifulSoup(web_html, 'lxml')\n",
    "    \n",
    "        rollbacks = soup.find_all('div', class_ = 'rollback-result-wrapper')\n",
    "        \n",
    "        #print(department)\n",
    "        \n",
    "        for products in rollbacks:\n",
    "            product_name = products.find('div', style = 'max-height:3em;overflow:hidden').text\n",
    "            product_price = products.find('span', class_ = 'price-characteristic')\n",
    "            if (products.find('span', class_ = 'price-characteristic')):\n",
    "                #print(product_name)\n",
    "                #print(product_price.text)\n",
    "                records.append((product_name, product_price.text))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#First lets get all information regaurding the beds\n",
    "records = []\n",
    "for i in range(25):\n",
    "    url = 'https://www.walmart.com/browse/home/beds/4044_103150_102547_91837?page=' + str(i+1)\n",
    "    web_html = requests.get(url).text\n",
    "    soup = BeautifulSoup(web_html, 'lxml')\n",
    "    \n",
    "    products = soup.find_all('div', class_ = 'search-result-gridview-item-wrapper')\n",
    "    print(products)\n",
    "    for product in products:\n",
    "        product_name = product.find('div', class_ = 'search-result-product-title gridview').text\n",
    "        if product_name:\n",
    "            records.append(product_name)\n",
    "    print(records)\n",
    "    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Name'])\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.walmart.com/browse/toys/board-games/4171_4191_133123?page=2'\n",
    "web_html = requests.get(url).text\n",
    "soup = BeautifulSoup(web_html, 'lxml')\n",
    "    \n",
    "products = soup.find_all('div', class_ = 'search-result-gridview-item-wrapper')\n",
    "print(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path=r'/Users/michael/Downloads/geckodriver')\n",
    "url = 'https://www.walmart.com/browse/toys/board-games/4171_4191_133123?page=2'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "results = soup.find_all('div', {'data-type': 'items'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educational Insights Pancake Pile-Up!, Sequence Relay Game: Preschool Game for Preschoolers & Toddlers, Ages 4+\n"
     ]
    }
   ],
   "source": [
    "item = results[0]\n",
    "title = item.find('div', class_ = 'search-result-product-title gridview').text\n",
    "if 'Product Title' in title:\n",
    "    title = title[13:]\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$15.99\n"
     ]
    }
   ],
   "source": [
    "price = item.find('span', class_ = 'price-group').text\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalize the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item):\n",
    "    title = item.find('div', class_ = 'search-result-product-title gridview').text\n",
    "    if 'Product Title' in title:\n",
    "        title = title[13:]\n",
    "        \n",
    "    # Error handling to get the price\n",
    "    try:\n",
    "        price = item.find('span', class_ = 'price-group').text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    result = (title, price)\n",
    "    return result\n",
    "\n",
    "def walmart_inventory_toys():\n",
    "    '''\n",
    "    This will return a full csv file of all of the walmart products available on walmart.com for board games.\n",
    "    TODO: Every category of products sold by walmart\n",
    "    '''\n",
    "    \n",
    "    records = []\n",
    "    dropship_products = []\n",
    "    \n",
    "    # start the driver\n",
    "    driver = webdriver.Firefox(executable_path=r'/Users/michael/Downloads/geckodriver')\n",
    "    \n",
    "    categories = ['camping-gear/shop-camping-brands/4125_546956_4128_2487866']\n",
    "    #'trampolines/4125_1224931_5230']#,'swing-sets/4171_14521_6449441','slides/4171_14521_4088179']\n",
    "    \n",
    "    for category in categories:\n",
    "        for i in range(25):\n",
    "            url = 'https://www.walmart.com/browse/toys/' + category + '?page=' + str(i+1)\n",
    "            driver.get(url)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            results = soup.find_all('div', {'data-type': 'items'})\n",
    "            \n",
    "            # Creating the record from all of the results\n",
    "            for item in results:\n",
    "                record = extract_record(item)\n",
    "                if record:\n",
    "                    records.append(record)\n",
    "    driver.close()\n",
    "    \n",
    "    #for record in records:\n",
    "    #    try:\n",
    "    #        amazon_record = find_amazon_prices(record[0])\n",
    "    #        computational_record = float(record[1].strip('$,'))\n",
    "    #        #Error Handling\n",
    "    #        if len(amazon_record) > 0:\n",
    "    #            if len(amazon_record[0]) == 3:\n",
    "    #                computational_amazon_record = float(amazon_record[0][2].strip('$,'))\n",
    "    #                if computational_record >= computational_amazon_record:\n",
    "    #                    print('Success!')\n",
    "    #                    dropship_products.append(record)\n",
    "    #    except ValueError:\n",
    "    #        print('Failure!')\n",
    "    #    except TypeError:\n",
    "    #        print('Failure!')\n",
    "        \n",
    "    with open('results.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Name', 'Price'])\n",
    "        writer.writerows(records)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6cced75c5bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwalmart_inventory_toys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-562852f82e2c>\u001b[0m in \u001b[0;36mwalmart_inventory_toys\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Creating the record from all of the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mrecords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-562852f82e2c>\u001b[0m in \u001b[0;36mextract_record\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'search-result-product-title gridview'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'Product Title'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "walmart_inventory_toys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'r', newline='') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        print(line_count)\n",
    "        line_count+=1\n",
    "        #if line_count != 0:\n",
    "        #    records = find_amazon_prices(row[0])\n",
    "        #    if records[0][2] >= row[1]:\n",
    "        #        print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term):\n",
    "    '''\n",
    "    Creates correct format of url from a specific search term.\n",
    "    Parameters:\n",
    "    --------------------------------------------\n",
    "    search_term: string of product that is wanted to be searched.\n",
    "    '''\n",
    "    template = 'https://www.amazon.com/s?k={}&ref=nb_sb_noss'\n",
    "    search_term = search_term.replace(' ', '+')\n",
    "    return(template.format(search_term))\n",
    "\n",
    "def extract_record_amazon(item):\n",
    "    '''\n",
    "    Extract and return data from a single record.\n",
    "    Parameters:\n",
    "    ---------------------------------------------\n",
    "    item: one search result from the search term.\n",
    "    '''\n",
    "    \n",
    "    #description and url\n",
    "    atag = item.h2.a\n",
    "    description = atag.text\n",
    "    url = 'https://www.amazon.com' + atag.get('href')\n",
    "    \n",
    "    #Price\n",
    "    try:\n",
    "        price = item.find('span', class_ = 'a-price').find('span', class_ = 'a-offscreen').text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    #Tuple of description, url, and price\n",
    "    results = (description, url, price)\n",
    "    return results\n",
    "\n",
    "def find_amazon_prices(search_term):\n",
    "    '''\n",
    "    Finds the prices of a search term and returns their description and price.\n",
    "    Parameters:\n",
    "    ---------------------------------------------\n",
    "    search_term: string of product we will be searching the price for on amazon.\n",
    "    '''\n",
    "    \n",
    "    #start the driver\n",
    "    driver = webdriver.Firefox(executable_path=r'/Users/michael/Downloads/geckodriver')\n",
    "    \n",
    "    records = []\n",
    "    url = get_url(search_term)\n",
    "    \n",
    "    #Get the information from each item in the search\n",
    "    driver.get(url.format())\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    results = soup.find('div', {'data-component-type': 's-search-result'})\n",
    "    for item in results:\n",
    "        record = extract_record_amazon(item)\n",
    "        if record:\n",
    "            records.append(record)\n",
    "    driver.close()\n",
    "    return records\n",
    "    #save data to something, right now a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "record = find_amazon_prices('trampoline')\n",
    "print(len(record[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
